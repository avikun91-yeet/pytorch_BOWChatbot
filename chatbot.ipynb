{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_K_xCLNY8_Tl",
        "outputId": "617a951d-05d3-49eb-df7a-77d46a97f10c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 0. 0. 1.]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except LookupError:\n",
        "    nltk.download('punkt_tab')\n",
        "\n",
        "def tokenize(sentence):\n",
        "  return nltk.word_tokenize(sentence)\n",
        "\n",
        "def stem(word):\n",
        "  return stemmer.stem(word.lower())\n",
        "\n",
        "def bag_of_words(tokenized_sentence, all_words):\n",
        "  tokenized_sentence = [stem(w) for w in tokenized_sentence]\n",
        "\n",
        "  bag = np.zeros(len(all_words), dtype = np.float32)\n",
        "\n",
        "  for idx, w in enumerate(all_words):\n",
        "    if w in tokenized_sentence:\n",
        "      bag[idx] = 1.0\n",
        "  return bag\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#generating the dataset"
      ],
      "metadata": {
        "id": "dmtDcIlgEIFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import numpy\n",
        "\n",
        "\n",
        "with open(\"/content/intents.json\", \"r\") as f:\n",
        "  intents = json.load(f)\n",
        "\n",
        "all_words= []\n",
        "tags = []\n",
        "xy = []\n",
        "\n",
        "for intent in intents['intents']:\n",
        "  tag = intent['tag']\n",
        "  tags.append(tag)\n",
        "\n",
        "  for pattern in intent['patterns']:\n",
        "    w = tokenize(pattern)\n",
        "    all_words.extend(w)\n",
        "\n",
        "    xy.append((w, tag))\n",
        "\n",
        "ignore_words = [\",\", '.', '!', \"?\"]\n",
        "all_words = [stem(word) for word in all_words if word not in ignore_words]\n",
        "print(all_words)\n",
        "\n",
        "all_words = sorted(set(all_words))\n",
        "tags = sorted(set(tags))\n",
        "\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for pattern_sentence, tag in xy:\n",
        "  bag = bag_of_words(pattern_sentence, all_words)\n",
        "  X_train.append(bag)\n",
        "\n",
        "  label = tags.index(tag)\n",
        "\n",
        "  y_train.append(label)\n",
        "\n",
        "X_train = numpy.array(X_train)\n",
        "y_train = numpy.array(y_train)\n",
        "\n",
        "\n",
        "class ChatDataset():\n",
        "  def __init__(self):\n",
        "    self.n_samples = len(X_train)\n",
        "    self.x_data = X_train\n",
        "    self.y_data = y_train\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.x_data[index], self.y_data[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "#hyperParameter\n",
        "batch_size =8\n",
        "input_size = len(all_words)\n",
        "hidden_size = 32\n",
        "output_size = len(tags)\n",
        "learning_rate = 0.01\n",
        "epochs = 100\n",
        "\n",
        "\n",
        "dataset = ChatDataset()\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NytenJ0TFwtU",
        "outputId": "7e69f623-f0bd-4785-abfa-39bd0d2cb520"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hi', 'how', 'are', 'you', 'is', 'anyon', 'there', 'hello', 'good', 'day', 'what', 'up', 'how', 'are', 'ya', 'heyi', 'whatsup', 'cya', 'see', 'you', 'bye', 'bye', 'see', 'you', 'later', 'goodby', 'i', 'am', 'leav', 'bye', 'have', 'a', 'good', 'day', 'talk', 'to', 'you', 'later', 'tyyl', 'i', 'got', 'to', 'go', 'gtg', 'what', 'is', 'the', 'name', 'of', 'your', 'develop', 'what', 'is', 'the', 'name', 'of', 'your', 'creator', 'what', 'is', 'the', 'name', 'of', 'the', 'develop', 'what', 'is', 'the', 'name', 'of', 'the', 'creator', 'who', 'creat', 'you', 'your', 'develop', 'your', 'creator', 'who', 'are', 'your', 'develop', 'develop', 'you', 'are', 'made', 'by', 'you', 'are', 'made', 'by', 'whom', 'who', 'creat', 'you', 'who', 'creat', 'you', 'creator', 'who', 'made', 'you', 'who', 'design', 'you', 'name', 'your', 'name', 'do', 'you', 'have', 'a', 'name', 'what', 'are', 'you', 'call', 'what', 'is', 'your', 'name', 'what', 'should', 'i', 'call', 'you', 'what', 'your', 'name', 'what', 'are', 'you', 'who', 'are', 'you', 'who', 'is', 'thi', 'what', 'am', 'i', 'chat', 'to', 'who', 'am', 'i', 'take', 'to', 'what', 'are', 'you', 'time', 'of', 'colleg', 'what', 'is', 'colleg', 'time', 'work', 'day', 'when', 'are', 'you', 'guy', 'open', 'what', 'are', 'your', 'hour', 'hour', 'of', 'oper', 'when', 'is', 'the', 'colleg', 'open', 'colleg', 'time', 'what', 'about', 'colleg', 'time', 'is', 'colleg', 'open', 'on', 'saturday', 'tell', 'someth', 'about', 'colleg', 'time', 'what', 'is', 'the', 'colleg', 'hour', 'when', 'should', 'i', 'come', 'to', 'colleg', 'when', 'should', 'i', 'attend', 'colleg', 'what', 'is', 'my', 'colleg', 'time', 'colleg', 'time', 'time', 'colleg', 'more', 'info', 'contact', 'info', 'how', 'to', 'contact', 'colleg', 'colleg', 'telephon', 'number', 'colleg', 'number', 'what', 'is', 'your', 'contact', 'no', 'contact', 'number', 'how', 'to', 'call', 'you', 'colleg', 'phone', 'no', 'how', 'can', 'i', 'contact', 'you', 'can', 'i', 'get', 'your', 'phone', 'number', 'how', 'can', 'i', 'call', 'you', 'phone', 'number', 'phone', 'no', 'call', 'list', 'of', 'cours', 'list', 'of', 'cours', 'offer', 'list', 'of', 'cours', 'offer', 'in', 'cbpgec', 'what', 'are', 'the', 'cours', 'offer', 'in', 'your', 'colleg', 'cours', 'cours', 'offer', 'cours', 'offer', 'in', 'cbpgec', 'cours', 'you', 'offer', 'branch', 'cours', 'avail', 'at', 'gec', 'branch', 'avail', 'at', 'gec', 'what', 'are', 'the', 'cours', 'in', 'gec', 'what', 'are', 'branch', 'in', 'gec', 'what', 'are', 'cours', 'in', 'gec', 'branch', 'avail', 'in', 'gec', 'can', 'you', 'tell', 'me', 'the', 'cours', 'avail', 'in', 'gec', 'can', 'you', 'tell', 'me', 'the', 'branch', 'avail', 'in', 'gec', 'civil', 'engin', 'civil', 'it', 'it', 'inform', 'about', 'fee', 'inform', 'on', 'fee', 'tell', 'me', 'the', 'fee', 'colleg', 'fee', 'fee', 'per', 'semest', 'what', 'is', 'the', 'fee', 'of', 'each', 'semest', 'what', 'is', 'the', 'fee', 'of', 'each', 'year', 'what', 'is', 'fee', 'what', 'is', 'the', 'fee', 'how', 'much', 'is', 'the', 'fee', 'fee', 'for', 'first', 'year', 'fee', 'about', 'the', 'fee', 'tell', 'me', 'someth', 'about', 'the', 'fee', 'where', 'is', 'the', 'colleg', 'locat', 'colleg', 'is', 'locat', 'at', 'where', 'is', 'colleg', 'where', 'is', 'colleg', 'locat', 'address', 'of', 'colleg', 'how', 'to', 'reach', 'colleg', 'colleg', 'locat', 'colleg', 'address', 'where', 'the', 'colleg', 'how', 'can', 'i', 'reach', 'colleg', 'what', 'is', 'the', 'colleg', 'address', 'what', 'is', 'the', 'address', 'of', 'colleg', 'address', 'locat', 'hostel', 'facil', 'hostel', 'serviv', 'hostel', 'locat', 'hostel', 'address', 'hostel', 'facil', 'hostel', 'fee', 'doe', 'colleg', 'provid', 'hostel', 'is', 'there', 'ani', 'hostel', 'where', 'is', 'hostel', 'do', 'you', 'have', 'hostel', 'do', 'you', 'guy', 'have', 'hostel', 'hostel', 'hostel', 'capac', 'what', 'is', 'the', 'hostel', 'fee', 'how', 'to', 'get', 'in', 'hostel', 'what', 'is', 'the', 'hostel', 'address', 'how', 'far', 'is', 'hostel', 'from', 'colleg', 'hostel', 'colleg', 'distanc', 'where', 'is', 'the', 'hostel', 'how', 'big', 'is', 'the', 'hostel', 'distanc', 'between', 'colleg', 'and', 'hostel', 'distanc', 'between', 'hostel', 'and', 'colleg', 'event', 'organis', 'list', 'of', 'event', 'list', 'of', 'event', 'organis', 'in', 'colleg', 'list', 'of', 'event', 'conduct', 'in', 'colleg', 'what', 'event', 'are', 'conduct', 'in', 'colleg', 'are', 'there', 'ani', 'event', 'held', 'at', 'colleg', 'event', 'function', 'what', 'are', 'the', 'event', 'tell', 'me', 'about', 'event', 'what', 'about', 'event', 'document', 'to', 'bring', 'document', 'need', 'for', 'admis', 'document', 'need', 'at', 'the', 'time', 'of', 'admiss', 'document', 'need', 'dure', 'admiss', 'document', 'requir', 'for', 'admis', 'document', 'requir', 'at', 'the', 'time', 'of', 'admiss', 'document', 'requir', 'dure', 'admiss', 'what', 'document', 'are', 'requir', 'for', 'admiss', 'which', 'document', 'to', 'bring', 'for', 'admiss', 'document', 'what', 'document', 'do', 'i', 'need', 'what', 'document', 'do', 'i', 'need', 'for', 'admiss', 'document', 'need', 'size', 'of', 'campu', 'build', 'size', 'how', 'mani', 'floor', 'doe', 'colleg', 'have', 'floor', 'in', 'colleg', 'floor', 'in', 'colleg', 'how', 'tall', 'is', 'cbpgec', 'colleg', 'build', 'floor', 'syllabu', 'for', 'it', 'what', 'is', 'the', 'inform', 'technolog', 'syllabu', 'syllabu', 'timet', 'what', 'is', 'it', 'syllabu', 'syllabu', 'what', 'is', 'next', 'lectur', 'is', 'there', 'ani', 'librari', 'librari', 'facil', 'librari', 'facil', 'do', 'you', 'have', 'librari', 'doe', 'the', 'colleg', 'have', 'librari', 'facil', 'colleg', 'librari', 'where', 'can', 'i', 'get', 'book', 'book', 'facil', 'where', 'is', 'librari', 'librari', 'tell', 'me', 'about', 'librari', 'how', 'mani', 'librari', 'how', 'is', 'colleg', 'infrastructur', 'infrastructur', 'colleg', 'infrastructur', 'food', 'facil', 'canteen', 'facil', 'canteen', 'facil', 'is', 'there', 'ani', 'canteen', 'is', 'there', 'a', 'cafetaria', 'in', 'colleg', 'doe', 'colleg', 'have', 'canteen', 'where', 'is', 'canteen', 'where', 'is', 'cafetaria', 'canteen', 'cafetaria', 'food', 'menu', 'food', 'in', 'canteen', 'what', 'there', 'on', 'menu', 'what', 'is', 'avail', 'in', 'colleg', 'canteen', 'what', 'food', 'can', 'we', 'get', 'in', 'colleg', 'canteen', 'what', 'is', 'colleg', 'placement', 'which', 'compani', 'visit', 'in', 'colleg', 'what', 'is', 'averag', 'packag', 'compani', 'visit', 'packag', 'placement', 'recruit', 'compani', 'who', 'is', 'it', 'hod', 'where', 'is', 'it', 'hod', 'it', 'hod', 'name', 'of', 'it', 'hod', 'who', 'is', 'civil', 'hod', 'where', 'is', 'civil', 'hod', 'civil', 'hod', 'name', 'of', 'civil', 'hod', 'who', 'is', 'mechan', 'hod', 'where', 'is', 'mechan', 'hod', 'mechan', 'hod', 'name', 'of', 'mechan', 'hod', 'what', 'is', 'the', 'name', 'of', 'princip', 'whatv', 'is', 'the', 'princip', 'name', 'princip', 'name', 'who', 'is', 'colleg', 'princip', 'where', 'is', 'princip', \"'s\", 'offic', 'princip', 'name', 'of', 'princip', 'exam', 'date', 'exam', 'schedul', 'when', 'is', 'semest', 'exam', 'semest', 'exam', 'timet', 'sem', 'semest', 'exam', 'when', 'is', 'exam', 'exam', 'timet', 'exam', 'date', 'when', 'is', 'semest', 'what', 'is', 'the', 'process', 'of', 'admiss', 'what', 'is', 'the', 'admiss', 'process', 'how', 'to', 'take', 'admiss', 'in', 'your', 'colleg', 'what', 'is', 'the', 'process', 'for', 'admiss', 'admiss', 'admiss', 'process', 'what', 'facil', 'colleg', 'provid', 'colleg', 'facil', 'what', 'are', 'colleg', 'facil', 'facil', 'facil', 'provid', 'max', 'number', 'of', 'student', 'number', 'of', 'seat', 'per', 'branch', 'number', 'of', 'seat', 'in', 'each', 'branch', 'maximum', 'number', 'of', 'seat', 'maximum', 'student', 'intak', 'what', 'is', 'colleg', 'intak', 'how', 'mani', 'stundent', 'are', 'taken', 'in', 'each', 'branch', 'seat', 'allot', 'seat', 'colleg', 'dress', 'code', 'colleg', 'dresscod', 'what', 'is', 'the', 'uniform', 'can', 'we', 'wear', 'casual', 'doe', 'colleg', 'have', 'an', 'uniform', 'is', 'there', 'ani', 'uniform', 'uniform', 'what', 'about', 'uniform', 'do', 'we', 'have', 'to', 'wear', 'uniform', 'what', 'are', 'the', 'differ', 'committ', 'in', 'colleg', 'differ', 'committe', 'in', 'colleg', 'are', 'there', 'ani', 'committe', 'in', 'colleg', 'give', 'me', 'committe', 'detail', 'committe', 'how', 'mani', 'committe', 'are', 'there', 'in', 'colleg', 'i', 'love', 'you', 'will', 'you', 'marri', 'me', 'do', 'you', 'love', 'me', 'fuck', 'bitch', 'shut', 'up', 'hell', 'stupid', 'idiot', 'dumb', 'ass', 'asshol', 'fucker', 'holiday', 'when', 'will', 'semest', 'start', 'when', 'will', 'semest', 'end', 'when', 'is', 'the', 'holiday', 'list', 'of', 'holiday', 'about', 'vacat', 'about', 'holiday', 'when', 'is', 'vacat', 'when', 'is', 'holiday', 'how', 'long', 'will', 'be', 'the', 'vacat', 'okk', 'oki', 'nice', 'work', 'well', 'done', 'good', 'job', 'thank', 'for', 'the', 'help', 'thank', 'you', 'it', 'ok', 'thank', 'k', 'ok', 'okay', 'what', 'can', 'you', 'do', 'what', 'are', 'the', 'thing', 'you', 'can', 'do', 'thing', 'you', 'can', 'do', 'what', 'can', 'u', 'do', 'for', 'me', 'how', 'u', 'can', 'help', 'me', 'whi', 'i', 'should', 'use', 'you', 'rag', 'is', 'rag', 'practic', 'activ', 'in', 'colleg', 'doe', 'colleg', 'have', 'ani', 'antirag', 'facil', 'is', 'there', 'ani', 'rag', 'case', 'is', 'rag', 'done', 'here', 'rag', 'junior', 'rag', 'histori', 'rag', 'incid', 'hod', 'hod', 'name', 'who', 'is', 'the', 'hod', 'dtc', 'bu', 'rout', 'mode', 'of', 'transport', 'how', 'to', 'get', 'to', 'colleg', 'buse', 'for', 'colleg', 'colleg', 'buse', 'bu', 'rout', 'list', 'of', 'buse', 'for', 'travel', 'doe', '835', 'goe', 'to', 'colleg', 'doe', '835', 'goe', 'to', 'rawta', 'mor', 'nearest', 'metro', 'station', 'what', 'is', 'the', 'nearest', 'metro', 'station', 'which', 'metro', 'station', 'is', 'near', 'closest', 'metro', 'station', 'which', 'metro', 'station', 'is', 'closest', 'nearbi', 'metro', 'station', 'metro', 'metro', 'station', 'nearbi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#model"
      ],
      "metadata": {
        "id": "13NK7jdQi69Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.l2 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.l3 = nn.Linear(hidden_size, output_size)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.l2(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.l3(out)\n",
        "    return out\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = NeuralNet(input_size, hidden_size, output_size)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  for (words, labels) in train_loader:\n",
        "    words = words.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    output = model(words)\n",
        "    loss = criterion(output, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if (epoch + 1) % 10 == 0:\n",
        "    print(f'epoch {epoch+1}/{epochs}, loss={loss.item():.4f}')\n",
        "\n",
        "print(f'final loss, loss={loss.item():.4f}')\n",
        "\n",
        "model_state = model.state_dict()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4r5Vt0foi6Rm",
        "outputId": "d11f390f-6463-43c7-8c0d-243e3a7f19f8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10/100, loss=0.0005\n",
            "epoch 20/100, loss=0.0004\n",
            "epoch 30/100, loss=0.0011\n",
            "epoch 40/100, loss=0.0003\n",
            "epoch 50/100, loss=0.0000\n",
            "epoch 60/100, loss=0.0001\n",
            "epoch 70/100, loss=0.0001\n",
            "epoch 80/100, loss=0.0000\n",
            "epoch 90/100, loss=0.0000\n",
            "epoch 100/100, loss=0.0001\n",
            "final loss, loss=0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#chatting"
      ],
      "metadata": {
        "id": "u0BVtThX6OSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "model.eval()\n",
        "\n",
        "bot_name = \"sam\"\n",
        "output_list = []\n",
        "input_list = ['hi how are you', 'what is your name', \"tutturu\", 'do you have a hostel']\n",
        "for input_sentence in input_list:\n",
        "\n",
        "  input_sentence = tokenize(input_sentence)\n",
        "  X = bag_of_words(input_sentence, all_words)\n",
        "  X = X.reshape(1, X.shape[0])\n",
        "  X = torch.from_numpy(X)\n",
        "  output = model(X)\n",
        "\n",
        "  _, predicted = torch.max(output, dim = 1)\n",
        "  tag = tags[predicted.item()]\n",
        "  probs = torch.softmax(output, dim = 1)\n",
        "  prob = probs[0][predicted.item()]\n",
        "  if prob.item() > 0.75:\n",
        "\n",
        "    for intent in intents['intents']:\n",
        "      if tag == intent['tag']:\n",
        "        print(random.choice(intent['responses']))\n",
        "  else:\n",
        "    print(\"I do not understand...\")\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QneVDh56QZt",
        "outputId": "1840acca-920e-44c8-d70e-45fb6c90e463"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good to see you again!\n",
            "You can call me Rawkush.\n",
            "I do not understand...\n",
            "Ch. Brahm Prakash Government Engineering College does  provide hostel facility\n"
          ]
        }
      ]
    }
  ]
}